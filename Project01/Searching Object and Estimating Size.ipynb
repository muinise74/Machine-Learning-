{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9aa07e6",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a75c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ad981",
   "metadata": {},
   "source": [
    "## Def middlePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c9ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA,ptB):\n",
    "    return ((ptA[0]+ptB[0])*0.5,(ptA[1]+ptB[1])*0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b63d9",
   "metadata": {},
   "source": [
    "## Load YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b65b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42426d4",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c129b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./img/sample07.jpg\")\n",
    "image = cv2.resize(image, None, fx=3, fy=3)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "height, width, channels = image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcf6ac",
   "metadata": {},
   "source": [
    "## Searching Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70035816",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3caf68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "boxes2 = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            # 좌표\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([[x, y], [x+w,y],[x,y+h],[x+w,y+h]])\n",
    "            boxes2.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a576744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09175792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[82, 183], [263, 183], [82, 322], [263, 322]],\n",
       " [[259, 110], [526, 110], [259, 418], [526, 418]],\n",
       " [[298, 113], [549, 113], [298, 412], [549, 412]],\n",
       " [[291, 138], [554, 138], [291, 437], [554, 437]],\n",
       " [[106, 161], [251, 161], [106, 316], [251, 316]],\n",
       " [[94, 174], [236, 174], [94, 329], [236, 329]],\n",
       " [[105, 174], [253, 174], [105, 330], [253, 330]],\n",
       " [[105, 186], [250, 186], [105, 338], [250, 338]],\n",
       " [[55, 310], [231, 310], [55, 337], [231, 337]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e6647",
   "metadata": {},
   "source": [
    "## Find MiddlePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603a5850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82. 183.]\n",
      " [263. 183.]\n",
      " [263. 322.]\n",
      " [ 82. 322.]]\n",
      "[[259. 110.]\n",
      " [526. 110.]\n",
      " [526. 418.]\n",
      " [259. 418.]]\n",
      "[[298. 113.]\n",
      " [549. 113.]\n",
      " [549. 412.]\n",
      " [298. 412.]]\n",
      "[[291. 138.]\n",
      " [554. 138.]\n",
      " [554. 437.]\n",
      " [291. 437.]]\n",
      "[[106. 161.]\n",
      " [251. 161.]\n",
      " [251. 316.]\n",
      " [106. 316.]]\n",
      "[[ 94. 174.]\n",
      " [236. 174.]\n",
      " [236. 329.]\n",
      " [ 94. 329.]]\n",
      "[[105. 174.]\n",
      " [253. 174.]\n",
      " [253. 330.]\n",
      " [105. 330.]]\n",
      "[[105. 186.]\n",
      " [250. 186.]\n",
      " [250. 338.]\n",
      " [105. 338.]]\n",
      "[[ 55. 310.]\n",
      " [231. 310.]\n",
      " [231. 337.]\n",
      " [ 55. 337.]]\n"
     ]
    }
   ],
   "source": [
    "middlePoints = []\n",
    "for box in boxes:\n",
    "    box = np.array(box)\n",
    "    box = perspective.order_points(box)\n",
    "    print(box)\n",
    "    (tl, tr, br, bl) = box\n",
    "    (tltrX, tltrY) = midpoint(tl, tr)\n",
    "    (blbrX, blbrY) = midpoint(bl, br)\n",
    "    (tlblX, tlblY) = midpoint(tl, bl)\n",
    "    (trbrX, trbrY) = midpoint(tr, br)\n",
    "    middlePoints.append([(tltrX, tltrY),(blbrX, blbrY),(tlblX, tlblY),(trbrX, trbrY)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ffb4b3",
   "metadata": {},
   "source": [
    "## Estimating Size and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0036036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boxes2, confidences, 0.5, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8502e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.0 251.0\n",
      "156.0 148.0\n",
      "27.0 176.0\n"
     ]
    }
   ],
   "source": [
    "orig = image.copy()\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "pixelsPerMetric = None\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes2[i]\n",
    "        color = colors[i]\n",
    "        label = str(classes[class_ids[i]])+\" \"+str(confidences[i])\n",
    "        cv2.rectangle(orig, boxes[i][0], boxes[i][3], color, 2)\n",
    "        cv2.putText(orig, label, (x, y + 30), font, 1, color, 2)\n",
    "        for (x, y) in boxes[i]:\n",
    "            cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "        for (x, y) in middlePoints[i]:\n",
    "            cv2.circle(orig, (int(x), int(y)), 5, (255, 0, 0), -1)\n",
    "    #     cv2.line(orig, middlePoints[i][0], middlePoints[i][1],(255, 0, 255), 2)\n",
    "    #     cv2.line(orig, middlePoints[i][2], middlePoints[i][3],(255, 0, 255), 2)\n",
    "        dA = dist.euclidean(middlePoints[i][0], middlePoints[i][1])\n",
    "        dB = dist.euclidean(middlePoints[i][2], middlePoints[i][3])\n",
    "        print(dA,dB)\n",
    "        if pixelsPerMetric is None:\n",
    "            pixelsPerMetric = dB / 3\n",
    "        dimA = dA / pixelsPerMetric\n",
    "        dimB = dB / pixelsPerMetric\n",
    "        cv2.putText(orig, \"{:.1f}in\".format(dimB),(int(middlePoints[i][0][0] - 15), int(middlePoints[i][0][1] - 10)), cv2.FONT_HERSHEY_SIMPLEX,0.65, (0, 0, 0), 2)\n",
    "        cv2.putText(orig, \"{:.1f}in\".format(dimA),(int(middlePoints[i][3][0] + 10), int(middlePoints[i][3][1])), cv2.FONT_HERSHEY_SIMPLEX,0.65, (0, 0, 0), 2)\n",
    "cv2.imshow(\"Image\", orig)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "172.543px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
